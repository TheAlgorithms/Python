# Машинное обучение

Машинное обучение — это область искусственного интеллекта, которая использует статистические методы, чтобы дать компьютерным системам возможность "обучаться" на данных без явного программирования.

***Примечание: Некоторые файлы в этом каталоге были помечены как `.broken.txt` и были пропущены.***

## Алгоритмы и концепции

### Ассоциативные правила
*   **Apriori (`apriori_algorithm.py`)**: Классический алгоритм для поиска частых наборов предметов в транзакционных базах данных.
*   **FP-Growth (`frequent_pattern_growth.py`)**: Эффективный алгоритм для поиска частых наборов предметов, который использует древовидную структуру (FP-Tree) для избежания дорогостоящей генерации кандидатов.

### Классификация
*   **Gradient Boosting Classifier (`gradient_boosting_classifier.py`)**: Реализация градиентного бустинга, который последовательно строит ансамбль слабых учеников (деревьев решений) для создания сильного классификатора.
*   **k-Nearest Neighbors (k-NN) (`k_nearest_neighbours.py`)**: Простой алгоритм, который классифицирует новую точку данных на основе большинства голосов её `k` ближайших соседей.
*   **Linear Discriminant Analysis (LDA) (`linear_discriminant_analysis.py`)**: Статистический метод для классификации, который предполагает, что данные каждого класса имеют гауссово распределение с общей ковариацией.
*   **Logistic Regression (`logistic_regression.py`)**: Алгоритм для бинарной классификации, который моделирует вероятность принадлежности к классу с помощью сигмоидной функции и оптимизируется градиентным спуском.
*   **Multilayer Perceptron (`multilayer_perceptron_classifier.py`)**: Пример использования многослойного перцептрона из библиотеки `scikit-learn` для задачи классификации.
*   **Support Vector Machines (SVM) (`support_vector_machines.py`, `sequential_minimum_optimization.py`)**: Реализации метода опорных векторов. Одна из них использует эффективный алгоритм SMO (Sequential Minimal Optimization) для обучения. SVM находит гиперплоскость, которая наилучшим образом разделяет классы в пространстве признаков.
*   **XGBoost Classifier (`xgboost_classifier.py`)**: Пример использования популярной библиотеки XGBoost (Extreme Gradient Boosting) для задачи классификации.

### Регрессия
*   **Decision Tree (`decision_tree.py`)**: Реализация регрессионного дерева решений, которое строит модель в виде дерева, рекурсивно разбивая данные для минимизации среднеквадратичной ошибки.
*   **Linear Regression (`linear_regression.py`)**: Реализация линейной регрессии с использованием градиентного спуска для нахождения линии наилучшего соответствия.
*   **Locally Weighted Linear Regression (`local_weighted_learning/`)**: Непараметрический метод, который строит локальную линейную модель для каждой точки прогноза, придавая больший вес ближайшим обучающим примерам.
*   **Polynomial Regression (`polynomial_regression.py`)**: Моделирует зависимость как полином m-й степени, решая задачу как частный случай множественной линейной регрессии.
*   **XGBoost Regressor (`xgboost_regressor.py`)**: Пример использования библиотеки XGBoost для задачи регрессии.

### Кластеризация
*   **K-Means (`k_means_clust.py`)**: Итеративный алгоритм, который разделяет набор данных на `k` кластеров, минимизируя сумму квадратов расстояний от каждой точки до центроида её кластера.
*   **Self-Organizing Map (SOM) (`self_organizing_map.py`)**: Тип нейронной сети, обучаемый без учителя для создания низкоразмерной карты входного пространства.

### Другие концепции
*   **A\* Search (`astar.py`)**: Алгоритм поиска, используемый для нахождения пути в графах, который здесь применяется в контексте машинного обучения.
*   **Automatic Differentiation (`automatic_differentiation.py`)**: Реализация автоматического дифференцирования в обратном режиме (backpropagation), фундаментального механизма для обучения нейронных сетей.
*   **Data Transformations (`data_transformations.py`)**: Функции для нормализации (масштабирование в диапазон [0, 1]) и стандартизации (среднее 0, стандартное отклонение 1) данных.
*   **Dimensionality Reduction (`dimensionality_reduction.py`)**: Реализации метода главных компонент (PCA) и линейного дискриминантного анализа (LDA) для уменьшения размерности данных.
*   **Gradient Descent (`gradient_descent.py`)**: Базовая реализация алгоритма градиентного спуска для минимизации функции стоимости.
*   **Loss Functions (`loss_functions.py`)**: Набор различных функций потерь, используемых для оценки ошибок моделей в задачах классификации и регрессии (например, Cross-Entropy, MSE, MAE, Hinge Loss).
*   **Scoring Functions (`scoring_functions.py`)**: Дополнительный набор метрик для оценки моделей (MAE, MSE, RMSE, RMSLE и др.).
*   **LSTM (`lstm/`)**: Пример использования нейронной сети с долгой краткосрочной памятью (LSTM) для прогнозирования временных рядов с помощью библиотеки Keras.
*   **MFCC (`mfcc.py`)**: Реализация извлечения Мел-частотных кепстральных коэффициентов — ключевых признаков для обработки аудио и речи.
*   **Similarity Search (`similarity_search.py`)**: Функции для поиска схожести между векторами с использованием евклидова расстояния и косинусного сходства.
*   **Word Frequency Functions (`word_frequency_functions.py`)**: Реализация базовых метрик для анализа текста, таких как TF, IDF и TF-IDF.
