{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging\n",
    "\n",
    "\n",
    "Bagging is an ensemble method used to reduce the variance of an estimator. Here the objective is to create several subsets of data from training sample chosen randomly with replacement. Each collection of subset data is used to train their decision trees. As a result, we get an ensemble of different models. Average of all the predictions from different trees are used which is more robust than a single decision tree classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Classifier\n",
    "\n",
    "\n",
    "Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree) by introducing randomization into its construction procedure and then making an ensemble out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# Reading the dataset\n",
    "df = pd.read_csv('-----enter the path of your dataset-----',names=['label', 'sms_message'])\n",
    "\n",
    "# labelling the values\n",
    "df['label'] = df.label.map({'ham':0, 'spam':1})\n",
    "\n",
    "# Splitting the dataset into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['sms_message'], \n",
    "                                                    df['label'], \n",
    "                                                    random_state=1)\n",
    "\n",
    "# Instantiating the CountVectorizer method\n",
    "count_vector = CountVectorizer()\n",
    "\n",
    "# Fitting the training data and returning the matrix.\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "\n",
    "# Transforming testing data and returning the matrix.\n",
    "testing_data = count_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Bagging Classifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Instantiating a BaggingClassifier with 210 weak learners.\n",
    "bag_mod = BaggingClassifier(n_estimators=210)\n",
    "\n",
    "\n",
    "# Fitting your BaggingClassifier to the training data\n",
    "bag_mod.fit(training_data, y_train)\n",
    "\n",
    "\n",
    "# Predicting using BaggingClassifier on the test data\n",
    "bag_preds = bag_mod.predict(testing_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring the model\n",
    "print('Accuracy score: ', format(accuracy_score(y_test, bag_preds)))\n",
    "print('Precision score: ', format(precision_score(y_test, bag_preds)))\n",
    "print('Recall score: ', format(recall_score(y_test, bag_preds)))\n",
    "print('F1 score: ', format(f1_score(y_test, bag_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
